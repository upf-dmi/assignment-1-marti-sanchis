---
title: "Hands-on 1"
author: "Mart√≠ Sanchis Llovera (marti.sanchos01@estudiant.upf.edu)"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"      
output:
  html_document:
    toc: true
    fig_caption: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Analysis of the Heart Disease Dataset 
Load the data from
[here](https://raw.githubusercontent.com/jpinero/DMI_2021/main/datasets/heart_disease_dataset.csv), and the description is [here](https://raw.githubusercontent.com/jpinero/DMI_2021/main/datasets/heart_disease_description.txt). 
The original dataset comes from [here](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) and corresponds to the [processed cleveland data](https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data)

## Load DATA
```{r hd_load}
set.seed(123)
library(pacman)
p_load(DataExplorer, zCompositions, here, magrittr, tidyverse, GGally, mice)

dt <- read_delim(file = here("data", "heart_disease_dataset.csv"), delim = " ") %>%
  mutate(patient_id=NULL)

```

## Perform an EDA on the dataset

After loading the dataset with read_delim(), we can see that the dimensions of this tibble are 303 observations with 14 attributes, which are named as specified in the description file. However, there are two variables that don't match the variable type specified in the descriptions: as we see in the header and also in the summary, variables ca and thal are detected as characters but should be categorical variables, and also the rest of categorical variables are detected as floats. Using unique() in these two first commented variables, we see that the reason they are detected as characters is because missing data are coded as a question mark "?". There are no duplicated rows in this dataset.

To correctly parse the variables we use the mutate() function, setting all categorical variables as so (also labeling each factor as described in the description file), and also changing age variable to integer. The categorical variable heart disease diagnosis shows 4 different levels, while in the description the diagnosis can only be positive or negative, so we have changed the levels to positive and negative only. Moreover we rename variables so they have more meaningful names. 

```{r hd_eda_tibble}
dim(dt)
colnames(dt)

head(dt)
summary(dt)
unique(dt$ca)
unique(dt$thal)
unique(dt$num)
dt[duplicated(dt),]

### Numerical (Discrete/continuous)
# age (numeric discrete): Age in years
# trestbps (numeric): Resting blood pressure (mm Hg)
# chol (numeric): Serum cholesterol (mg/dl)
# thalach (numeric continuous): Maximum heart rate achieved
# oldpeak (numeric continuous): ST depression induced by exercise relative to rest

### Categorical
# sex (factor): 1 = male, 0 = female
# cp: (factor) Chest pain type (1: typical angina, 2: atypical angina, 3: non-anginal pain, 4: asymptomatic)
# fbs (factor): Fasting blood sugar > 120 mg/dl (1 = true, 0 = false)
# restecg (factor): Resting electrocardiographic results (0: normal, 1: ST-T wave abnormality, 2: left ventricular hypertrophy)
# exang (factor): Exercise-induced angina (1 = yes, 0 = no)
# slope (factor): Slope of the peak exercise ST segment (1: upsloping, 2: flat, 3: downsloping)
# ca (factor): Number of major vessels colored by fluoroscopy
# thal (factor): Thalassemia (3: normal, 6: fixed defect, 7: reversible defect)
# num (factor): Diagnosis of heart disease (1: > 50% diameter narrowing, 0: < 50% narrowing)

heart_disease <- dt %>%
  mutate(
    sex = factor(sex, levels = c("0", "1"), labels = c("female", "male")),
    cp = factor(cp, levels = c("1", "2", "3", "4"), labels = c("typical","atypical","non-anginal","asymptomatic")),
    trestbps = as.double(trestbps),
    chol = as.double(chol),
    fbs = factor(fbs, levels = c("0","1"),labels = c("<120mg/dl", ">120mg/dl")),
    restecg = factor(restecg, levels = c("0","1","2"), labels = c("normal", "abnormal", "hypertrophy")),
    thalach = as.double(thalach),
    exang = factor(exang, levels = c("0","1"),labels = c("not", "yes")),
    oldpeak = as.double(oldpeak),
    slope = factor(slope, levels = c("1","2","3"), labels = c("upsloping", "flat", "downsloping")),
    ca = factor(na_if(ca, "?"), levels = c("0","1","2","3")),
    thal = factor(na_if(thal, "?"), levels = c("3","6","7"), labels = c("normal", "fixed", "reversible")),
    num = factor(ifelse(num == "0", "negative", "positive"))
  ) %>% 
    rename(
      Gender=sex,
      Age=age,
      ChestPain = cp,
      RestingBloodPressure = trestbps,
      Cholesterol = chol,
      FastingBloodSugar = fbs,
      RestingECG = restecg,
      MaxHeartRate = thalach,
      ExerciseInducedAngina = exang,
      STDepression = oldpeak,
      Slope=slope,
      MajorVessels = ca,
      Thalassemia = thal,
      HeartDiseaseDiagnosis = num
  )
summary(heart_disease)
head(heart_disease)
```

We use the function zPatterns from the package zCompositions to plot the different patterns of missingness in this dataset. We can observe that very few observations have missing data, only in the two variables mentioned above: vessels_count and thalassemia. Also we can see that the missingness in the two variables are independent from each other, so most probably these are missing completely at random. Taking into account that only a 2% of observations contain missing data, we could just simply remove these records from the dataset.

We apply the function mice from package "mice" to input the missing data in the two categorical variables. For dat, we select the configuration "polyreg" used for imputing missing values for unordered categorical variables with more than 2 levels (non-binary). This method imputs missing data with a Bayesian polytomous regression model. The number of multiple imputations is set to 5 by default. This is the number of datasets generated by the algorithm, imputing different values in each accounting for statistical uncertainty. Later, the algorithm combines these imputations. This algorithm is assigning:
-For MajorVessels: 2 missing values to level 0 and 2 to level 1.
-Thalassemia: 1 missing value to level "normal", and 1 to level "reversible".

```{r hd_eda_missing_data}
heart_disease %>% 
  dplyr::select(c(Age,Gender,ChestPain,MajorVessels,Thalassemia,HeartDiseaseDiagnosis)) %>% 
  zPatterns(label = NA, bar.labels = TRUE)
# plot_missing(heart_disease,
#              title = "Missing Data",
#              ggtheme = theme_light())
imputed_data <- mice(heart_disease, method = "polyreg")

heart_disease_imputed <- complete(imputed_data)

summary(heart_disease %>% dplyr::select(MajorVessels,Thalassemia))
summary(heart_disease_imputed %>% dplyr::select(MajorVessels,Thalassemia))
```
Afterwards, we create two different tibbles containing only the numerical variables or the categorical variables. We use the pivot_longer function to reorganize the tibble in a way that the information of attribute is no longer a set of different columns but a single column. The levels of this column are the variable names. The second column contains the corresponding values for all levels. This allows us to make univariate plots with all variables within a single ggplo2 call:

- First we plot the histograms from the numerical variables with the density line. Also we use the qq-plots to visualize if they follow a normal-distribution or not. Mainly, variables age, choloesterol, max_hr and rest_bsp seem that could follow a normal distribution. However, both cholesterol and rest_bps appear to be slightly positively skewed with a heavier right tail and may present some outliers. On the other hand, max_hr shows a slight negative skewness with a heavier left tail. The distribution of variable st_depression is heavily zero-inflated and also probably present some outliers in its right tail, deviating the most from a normal distribution.
When checking the normality of the numerical variables with the shapiro.wilk test, the assumption of normality is rejected for all of them. We try to use the log values and still normality is rejected for most variables, except from cholesterol.

```{r hd_eda_univariate>_numerical}
numerical_long <- heart_disease_imputed %>% 
  pivot_longer(cols = where(is.numeric), names_to = "Variables", values_to = "Value") %>% 
  dplyr::select(Variables, Value)

numerical_long %>% ggplot(aes(x = Value)) + 
  geom_histogram(aes(y = after_stat(density)), bins=15, fill = "lightseagreen", color = "black") + 
  geom_density(bw=15) +
  facet_wrap(~ Variables, scales = "free") + 
  theme_minimal() +
  labs(title = "Histograms for Numeric Variables",
       x = "Value",
       y = "Frequency")

numerical_long %>% ggplot(aes(sample = Value)) +
  geom_qq() +
  geom_qq_line(color = "red") +
  facet_wrap(~ Variables, scales = "free") + 
  theme_minimal() +
  labs(title = "QQ Plots for Numeric Variables",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles")
numerical_long %>% 
  group_by(Variables) %>%
  summarise(
    p_value = shapiro.test(Value)$p.value)
numerical_long %>% 
  group_by(Variables) %>%
  summarise(
    p_value = shapiro.test(log(Value))$p.value)
```

In the univariate boxplots we can see that some variables like Cholesterol RestingBloodPressure and STDepression have in fact some outliers. However, in order to adress them, the mahalanobis_distance function from package rstatix. This is a multivariate algorithm that uses the mahalanobis distance to flag outliers, also taking into account the covariance matrix of the set of variables. In this way, some of the univariate outliers are not flagged as so. 

Only observations 153, 127 and 92 are identified as outliers. Looking at the boxplots, is very clear that each of these observations stands out as an outlier (above upper limit) because of its value for single variable: 153 because of cholesterol value, 127 because of RestingBloodPressure value and 92 because of STDepression value. Consequently, we decide to change a single value in each outlier observation for the corresponding variable using the upper whisker limit of the boxplot, computed as Q3 + 1.5 InterQuartileRange. After that, the mahalanobis_distance function doesn't detect more outliers.

```{r hd_outliers}
numerical_long %>% ggplot(aes(y = Value)) + 
  geom_boxplot() +
  geom_jitter(aes(x = 0), size=0.8) +
  facet_wrap(~ Variables, scales = "free") + 
  theme_minimal() +
  labs(title = "Histograms for Numeric Variables",
       x = "Value",
       y = "Frequency")

heart_disease_imputed %<>% add_column(rstatix::mahalanobis_distance(heart_disease_imputed) %>%
                                        dplyr::select(is.outlier)) %>% 
  mutate(id=row_number())
  
numerical_long <- heart_disease_imputed %>% 
  pivot_longer(cols = where(is.numeric)& !c("id"), 
               names_to = "Variables", 
               values_to = "Value") %>% 
  dplyr::select(Variables, Value, is.outlier, id)

numerical_long %>% ggplot(aes(y = Value)) + 
  geom_boxplot() +
  geom_jitter(aes(x = 0, colour = is.outlier), size=0.8) +
  geom_text(
    data = numerical_long %>% filter(is.outlier == TRUE),
    aes(x = 0, label = id), 
    hjust = -0.2, 
    size = 3.5, 
    color = "red" 
  ) +
  facet_wrap(~ Variables, scales = "free") + 
  theme_minimal() +
  labs(title = "Histograms for Numeric Variables",
       x = "Value",
       y = "Frequency") +
  scale_color_manual(values = c("FALSE" = "black", "TRUE" = "red"))

variables_outliers <- list(
  "Cholesterol" = 153,
  "RestingBloodPressure" = 127,
  "STDepression"  = 92)

for (var in names(variables_outliers)) {
  Q1 <- unname(quantile(heart_disease_imputed[[var]], 0.25))
  Q3 <- unname(quantile(heart_disease_imputed[[var]], 0.75))
  IQR <- Q3 - Q1
  upper_limit <- Q3 + 1.5 * IQR
  lower_limit <- Q1 - 1.5 * IQR
  heart_disease_imputed[variables_outliers[[var]],var] <- upper_limit
}

rstatix::mahalanobis_distance(heart_disease_imputed) %>%
  dplyr::select(is.outlier) %>% 
  any()
```
-Finishing this univariate part, we plot barplots for the categorical variables. We can see that many variables' levels are unbalanced. For example, fasting_bs, rest_ecg, slope, chest_pain, thalassemia and vessel count.

```{r hd_eda_univariate>_categorical}
categorical_long <- heart_disease_imputed %>% 
  pivot_longer(cols = where(is.factor), names_to = "Variables", values_to = "Value")%>% 
  dplyr::select(Variables, Value)

categorical_long %>% ggplot(aes(x = Value)) +
  geom_bar(fill = "firebrick") + 
  facet_wrap(~ Variables, scales = "free") +  
  theme_minimal() +
  theme(legend.position = "none") + 
  labs(title = "Barplots for Categorical Variables",
       x = "Level",
       y = "Frequency")

```

The scatter plots showed below, along with the correlation coefficients, show really poor correlation between numerical variables. The highest correlations are found in Max Heart Rate decreasing with Age, ST Depression decreasing with Max Heart Rate and Resting Blood Preassure increasing with Age.

```{r hd_eda_bivariate}
## Correltion test for numerical variables by HeartDiseaseDiagnosis
ggpairs(heart_disease_imputed,
        columns = c("Age", "RestingBloodPressure", "Cholesterol", "MaxHeartRate", "STDepression", "HeartDiseaseDiagnosis"),
        aes(color = HeartDiseaseDiagnosis),
        progress = FALSE) +  
  theme_minimal() +
  labs(title = "Pair Plot of Numerical Variables by Heart Disease Diagnosis")



## Chi-squared test for categorical variables
plot_chisq_fisher_barplot <- function(data, var1, var2) {
  contingency_table <- table(data[[var1]], data[[var2]])
  
  chi_square_result <- chisq.test(contingency_table)
  chi_p_value <- chi_square_result$p.value
  fisher_result <- fisher.test(contingency_table)
  fisher_p_value <- fisher_result$p.value
  
  p <- ggplot(data, aes_string(x = var1, fill = var2)) +
    geom_bar(position = "dodge") +
    labs(title = paste("Barplot of", var1, "by", var2),
         x = var1,
         y = "Frequency") +
    scale_fill_manual(values = c("#1f77b4", "#ff7f0e")) +  
    theme_minimal() +
    theme(plot.title = element_text(size = 16))  # Ajusta el tama√±o del t√≠tulo
  p + annotate("text", x = 1.5, y = max(table(data[[var2]])) * 1.05, 
               label = paste("Chi-sq p-value:", format(chi_p_value, scientific = TRUE, digits = 4)), 
               size = 5, hjust = 0.5, color = "black") +
    annotate("text", x = 1.5, y = max(table(data[[var2]])) * 0.95, 
             label = paste("Fisher p-value:", format(fisher_p_value, scientific = TRUE, digits = 4)), 
             size = 5, hjust = 0.5, color = "black")
}

plot_chisq_fisher_barplot(heart_disease_imputed, "Gender", "HeartDiseaseDiagnosis")
```

## Create visualizations in order to show which variables seem to be more associated with heart disease

```{r hd_plots}

```


# 2 Difference in mortality rates in hospitalized COVID-19 patients 
Using the supplementary material from the [Difference in mortality rates in hospitalized COVID-19 patients identified by cytokine profile clustering using a machine learning approach: An outcome prediction alternative](https://www.frontiersin.org/articles/10.3389/fmed.2022.987182/full), perform the following tasks

## Reproduce Figure 1 from the publication

```{r}

```


## Reproduce Figure 2 from the publication
but instead of representing the clusters in the annotation, represent the groups (G1 to G4)

```{r}

```

## Improve figure 2 of the publication
Add a second annotation with information of deathm and a third one with information of gender

```{r}

```


# session info {.unnumbered}

```{r, results='asis',  echo=FALSE, message=FALSE }
sessionInfo()
```
